\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[]{acl}
\usepackage{times}
\usepackage{latexsym}
\usepackage{comment}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Group 65 Progress Report:\\Asteroid Classification using Machine Learning}


\author{Claire Nielsen, Jake Read, Rebecca Di Filippo \\
  \texttt{\{nielsc2, readj9, diflilr\}@mcmaster.ca} }

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
% \begin{abstract}
% \end{abstract}

\section{Introduction}

\noindent There are tens of thousands of Near Earth Asteroids (NEAs) on orbit paths close to Earth, with more being discovered daily \citep{NASANEAs}. Some of these become classified as Potentially Hazardous Asteroids (PHAs), as they become large enough to potentially cause a problem. As more and more NEAs are discovered every day, it would be helpful to develop a machine learning classification system that would be able to classify NEAs to determine which could be hazardous. Classification of asteroids requires time-consuming analysis of a variety of features. An autonomous model would allow space agencies to dedicate more resources to observation of the detected PHAs and developing mitigation strategies. \newline

\noindent Accurate and expedient classification of asteroids is crucial to determining potential risks to planetary health. This project will develop a model to classify NEAs based on physical and orbital characteristics to determine which could be hazardous to Earth. This project will clean and pre-process the dataset, selects relevant features, and trains a model using machine learning to classify asteroids as hazardous or non-hazardous. We will handle class imbalance using techniques like oversampling( e.g., SMOTE)), or weighted loss, and then evaluate the model. \newline

\noindent The dataset we will use contains an existing classification for, as well as features of thousands of discovered asteroids. The dataset is derived from NASA and JPL's Small-body and Asteroid database. The dataset contains 45 features of any known object, and we will engineer a feature set that yields the best results, clean the data and handle imbalance. \newline

\section{Related Work}

\noindent \citet{NASANEOs} defines Potentially Hazardous Asteroids (PHAs) based on parameters that affect the asteroid's potential to be threatening, including its closest distance to Earth, size and albedo. There have been several systems developed using various machine learning models. \newline

\noindent Results of a comparison of machine learning models to classify NEAs were published in 2022, and included comparison of logistic regression, naive Bayes, support vector machines (SVMs), gradient boosting, and MultiLayer Perceptrons (MLPs). The article states that \textit{multilayer perception} and \textit{gradient boosting} yielded the most accurate results \citep{CompareML}. \newline

\noindent A further indicator of the performance of gradient boosting came from a classification project using the NGBoost classifier, a gradient boosting framework that uses natural gradient descent for optimization. Using NGBoost produced an overall accuracy of 99.22\% \citep{NGBoost}. \newline

\noindent Another article published in 2019 compares the Hierarchal Clustering Method (HCM) to a newer, \textit{supervised learning HCM} method. The supervised HCM method proved superior to the classical method, correctly identifying all asteroids within the target family and and yielding an accuracy of about 85\% \citep{HCM}. \newline

\noindent A different approach was taken by \citet{SVM}, who observed subgroups of NEAs with high concentrations of PHAs, to better determine which characteristics can be used as flags of hazardous asteroids. Using a \textit{Support Vector Machine (SVM)} model, the extracted subgroups of NEAs contained about 90\% of the real and virtual PHAs. \newline 

\section{Dataset}

\noindent We are using a public dataset available on Kaggle, licensed under Open Data Commons Open Database License, by user sakhawak18. The database is called \textit{Asteroid Dataset}, found \href{https://www.kaggle.com/datasets/sakhawat18/asteroid-dataset}{here} \cite{10.1007/978-981-19-7528-8_4}. As stated in the summary, it is officially maintained and updated weekly, and has a Kaggle-calculated usability score of 10.00. The original source of the data is NASA's Jet Propulsion Laboratory Small-Body and Asteroid databases, containing both orbital and physical properties for hundreds of thousands of known asteroids \citep{database}. \newline

\noindent The dataset contains orbital and physical properties of thousands of discovered and analyzed asteroids. There is a target label \texttt{pha} present, representing the classification to be predicted by the model. These are the features our model will use, and are as follows:

\begin{itemize}
    \item \textbf{Flags:} \texttt{neo} (Near-Earth Object flag), \texttt{pha} (Potentially Hazardous Asteroid flag, 1 = hazardous, 0 = non-hazardous)

    \item \textbf{Physical Properties:} \texttt{H} (absolute magnitude), \texttt{diameter} (km), \texttt{albedo} (surface reflectivity), \texttt{diameter\_sigma} (uncertainty in diameter)

    \item \textbf{Orbital Elements:}
    \begin{itemize}
        \item Core orbital parameters: \texttt{e} (eccentricity), \texttt{a} (semi-major axis), \texttt{q} (perihelion distance), \texttt{i} (inclination), \texttt{om} ($\Omega$, longitude of ascending node), \texttt{w} ($\omega$, argument of perihelion), \texttt{ma} (mean anomaly)
        \item Derived orbital distances: \texttt{ad} (aphelion distance), \texttt{moid} (minimum orbit intersection distance), \texttt{moid\_ld} (MOID in lunar distances)
        \item Motion and timing: \texttt{n} (mean motion), \texttt{tp} (time of perihelion passage), \texttt{per} (orbital period in days), \texttt{per\_y} (orbital period in years)
    \end{itemize}

    \item \textbf{Uncertainties (Standard Deviations):} \texttt{sigma\_e}, \texttt{sigma\_a}, \texttt{sigma\_q}, \texttt{sigma\_i}, \texttt{sigma\_om}, \texttt{sigma\_w}, \texttt{sigma\_ma}, \texttt{sigma\_ad}, \texttt{sigma\_n}, \texttt{sigma\_tp}, \texttt{sigma\_per}

    \item \textbf{Model Fit Quality:} \texttt{rms} (root-mean-square residual, indicating fit accuracy of the orbital solution)

    \item \textbf{Target Label:} \texttt{pha} (Potentially Hazardous Asteroid flag â€” the classification label to be predicted)
\end{itemize}

The dataset also contains identifier, metadata, epoch and reference data features that will not be used in our model. The excluded features are: 

\begin{itemize}
    \item \textbf{Identifiers and Metadata:} \texttt{id}, \texttt{spkid}, \texttt{full\_name}, \texttt{pdes}, \texttt{name}, \texttt{prefix}, \texttt{orbit\_id}, \texttt{class}

    \item \textbf{Epoch and Reference Data:} \texttt{epoch}, \texttt{epoch\_mjd} (Modified Julian Date), \texttt{epoch\_cal} (calendar format), \texttt{equinox}, \texttt{tp\_cal} (perihelion passage in calendar format) \newline 
\end{itemize}

\noindent We will import the dataset using the Kaggle API, complying with its terms of service. Once the dataset is imported it will then be preprocessed, which includes a number of steps. The dataset contains some non-numeric columns in the identifiers and metadata (including but not limited to \texttt{id}, \texttt{name}, and \texttt{class}) that will be dropped as they cannot contribute to prediction. Some categorical categories, including the \texttt{pha} flag, will be converted to numerical binary values and processed as such. Any string values remaining in the dataset will be forced to \texttt{NaN} to ensure that no unpredicted errors occur in processing. The resulting missing values will then be handled by converting them to the column mean. \newline

\section{Features}

\noindent As mentioned, the model handles most but not all features provided by the dataset. This is because the dataset provides data that is not required for predictive purposes, which in this case includes identifiers, metadata, epoch and reference data. The included features contain the data that is most relevant to the categorization of an NEA as hazardous. \newline

\noindent NASA categorizes PHAs based on the value of \texttt{moid} (minimum orbit intersection distance), \texttt{H} (absolute magnitude), and \texttt{albedo} (surface reflectivity). The minimum orbit intersection distance is the closest the asteroid will come to Earth on its natural orbit path, with hazardous asteroids having a \texttt{moid} $\leq 0.05$au, or astronomical units (149,597,870,700 m, which approximates the distance between the Earth and the sun). The absolute magnitude of an asteroid represents the visual magnitude an observer would record if the asteroid were placed exactly 1au away and 1au from the Sun at a zero phase angle (effectively measuring size). PHAs are characterized by an absolute magnitude \texttt{H} $\leq 22$. This magnitude translates to asteroids that are no more than 140m in diameter, and corresponds to an assumed \texttt{albedo} = 0.14. The albedo of an asteroid represents its ratio of the light received to light reflected by that body, ranging from 0 (pitch black) to 1 (perfect reflector). Our model will take in these features as well as the others to produce an accurate prediction of the \texttt{pha} flag. \newline

\noindent We are using feature selection in our model. Feature engineering involves creating new features based on overlapping/redundant features from the original dataset. We may have some very similar features, but at this point have chosen not to engineer them for use with this model. Our \textit{feature\textunderscore engineering} class contains code to select which feature sets to use. We will not be using embedding, as any relevant data to the prediction is represented numerically, and we do not have to process string data or images.

\section{Implementation}

\noindent When we started this project, our plan was to use a Gradient Boosted Trees model. We chose this model for a number of reasons. From research it seems like they handle structured tabular data well, manage non-linear relationships, and allow weighting for class imbalance, all of which apply to our dataset. Furthermore, research into existing solutions and related work confirmed that Gradient Boosted Trees have potential for and already have highly accurate results when classifying PHAs. \newline

\noindent The model we have implemented is a Histogram-based Gradient Boosting Classifier (HGBC). This model outperforms traditional Gradient Boosting with large sample sizes, which applies to this project. This will be referred to as a Main Model. The Main Model uses a logistic loss function for classification, since it is the only loss function available to a Histogram-based Gradient Boosting Classifier. Since we are performing binary classification, the model uses binary logistic loss, also known as binary cross-entropy. We have optimized the model using hyperparameter tuning, which the user can enable or disable. \newline

\noindent Histogram-based Gradient Boosting Classifiers are much faster than traditional Gradient Boosting Classifiers (GBCs). GBCs require sorting of all samples present for each feature, resulting in high node splitting complexity of $O(n_{features} * n_{samples}\log{}n_{samples})$ at every node. HGBCs do not use the costly operation of sorting samples and instead reference an implicitly sorted histogram. Building a histogram has complexity $O(n_{samples})$, so the node splitting complexity of HGBCs is $O(n_{features} * n_{samples})$, which is much lower \citep{ScikitHGBCs}. \newline

\noindent The program is run by running main.py, with potential arguments:
\begin{itemize}
    \item \texttt{-ht}, to run hyperparameter tuning before training the model. 
    \item \texttt{-fs}, to change the feature set used for training. Any combination may be used, default is all. 
    \item \texttt{-ms}, to specify a save path for the trained model. 
    \item \texttt{-ml}, to specify a save math to load the trained model from. \newline 
\end{itemize}

\noindent Assuming the program is run with default arguments, the data is then downloaded (or loaded from existing raw save) and preprocessed (or loaded from existing preprocessed save). The data is then split into training and testing data, with 80\% allocated to training and 20\% allocated to testing. After the test-train split, it is normalized. \newline

\noindent If desired, the hyperparameter tuning is then run on the Main Model, which finds the best parameters or the model by random search. This yields tuned hyperparameters for learning rate, maximum tree depth, and maximum number of boosting iterations (trees). \newline 

\noindent Each time the program runs, a Baseline Model is trained. The Baseline Model predicts the majority class (hazardous or non-hazardous) in dataset by counting which classifier occurs most frequently. Since the vast majority of samples are classified as non-hazardous, the Baseline Model predicts 0 for all samples. This Baseline Model exists only to establish a very weak baseline so that we can see that our Main Model performs better. If a Main Model has been previously trained, it is then loaded. If there is no existing model file, one is trained and saved for future use. The Main Model and Baseline Model are then both used to predict the testing data that was set aside during the earlier 80-20 train-test split. The predicted data is then evaluated, and the models' results are compared. \newline

\section{Results and Evaluation}

\noindent At this stage of the project, our model is performing quite well. As mentioned, we are using a train-test split of 80\% training data and 20\% testing data, with cross-validation used for hyperparameter tuning. We are evaluating our model's performance based on accuracy, precision, recall, and resulting F1 score, as well as through a confusion matrix. The F1 score is the most important measure as it represents a harmonic mean of the precision and recall of a model. We represent the performance of the Baseline Model compared to the Main Model in a bar graph: \newline

\begin{figure}[h]
  \includegraphics[width=\columnwidth]{../../src/plots/model_comparison_report.png}
  \caption{Bar graph comparing the Baseline Model's performance metrics to the Main Model with no Hyperparameter .}
  \label{fig:bar_graph}
\end{figure}

\noindent In this graph, we can see that the Baseline Model has incredibly high accuracy, and almost zero precision, recall, and F1 score. Since the baseline classifies all samples as non-hazardous, it results in a high accuracy score since most samples are correctly classified. However, since it incorrectly classifies all hazardous asteroids, every other score is zero. However, we can also see that our Main Model performs quite well. In the trial that produced this graph, the Main Model had: \newline \newline

\begin{table}[h]
  \centering
  \begin{tabular}{lll}
    \hline
    \textbf{Metric}           & \textbf{Score (\%)} \\
    \hline
    Accuracy    &   99.93   \\
    Precision   &   78.53   \\
    Recall      &   91.73   \\
    F1 Score    &   84.62   \\
    \hline
  \end{tabular}
  \caption{\label{trial_results}
    Main Model scores produced with no Hyperparameter Tuning. \newline
  }
\end{table} 

\noindent We also display confusion matrices to view predicted and actual true classification labels. The trial from above resulted in this confusion matrix for the Main Model: \newline

\begin{figure}[h]
  \includegraphics[width=\columnwidth]{../../src/plots/confusion_matrix_Main_Model_report.png}
  \caption{Confusion Matrix produced by Main Model with no Hyperparameter Tuning.}
  \label{fig:cm_1}
\end{figure}

\noindent The confusion matrix provides a visual representation of true vs. predicted classification. The dark green section represents samples that were correctly predicted to be non-hazardous, representing the vast majority of the dataset. The category with the second most samples is asteroids that the model predicted to be hazardous. This reinforces the high scores we saw previously for the Main Model's performance. \newline

\noindent Note that the above bar graph and confusion matrix represent the model being trained and run without running hyperparameter tuning. Hyperparameter tuning will improve the performance and scores of the main model by randomly searching for the best parameters for the model. Below is the confusion matrix produced by a model trained with hyperparameter tuning, and a comparison of the scores. 

\begin{figure}[h]
  \includegraphics[width=\columnwidth]{../../src/plots/confusion_matrix_Main_Model_report_2.png}
  \caption{Confusion Matrix produced by Main Model with Hyperparameter Tuning.}
  \label{fig:cm_2}
\end{figure}

\begin{table}[h]
  \centering
  \begin{tabular}{lll}
    \hline
    \textbf{Metric}           & \textbf{M Score (\%)} & \textbf{M + HT Score (\%)} \\
    \hline
    Accuracy    &   99.93   &   99.96   \\
    Precision   &   78.53   &   91.42   \\
    Recall      &   91.73   &   88.18   \\
    F1 Score    &   84.62   &   89.77   \\
    \hline
  \end{tabular}
  \caption{\label{tuning_results_compare}
    Comparison of Main Model with and without Hyperparameter Tuning. \newline
  }
\end{table} 

\noindent As shown in the confusion matrix, the tuned model correctly classifies an additional 71 samples as non-hazardous, however correctly classifies 15 fewer samples as hazardous. This net increase to correct identification is reflected in the scores shown in Table 2. The tuned model yielded an increase in accuracy, precision, and overall F1 score. \newline

\section{Feedback and Plans}

\noindent TA feedback was received on Monday, November 10th. The group presented the confusion matrix generated by our model, which was met with approval. The report was not near completion at this time, but we were advised to include many of our graphs and confusion matrices in the report for visual representation of our results. To reflect our implementation of this feedback, here is our List of Figures and List of Tables \newline

\listoffigures
\listoftables 

\medskip \noindent As the project progresses, we will work on refining our model by running with different feature sets to see which have the greatest impact on its performance. We will also work with different techniques to handle the class imbalance due to the much smaller number of hazardous asteroids in our dataset. \newline

\begin{comment}
\section{Template Notes}

You can remove this section or comment it out, as it only contains instructions for how to use this template. You may use subsections in your document as you find appropriate.

\subsection{Tables and figures}

See Table~\ref{citation-guide} for an example of a table and its caption.
See Figure~\ref{fig:experiments} for an example of a figure and its caption.


\begin{figure}[t]
  \includegraphics[width=\columnwidth]{example-image-golden}
  \caption{A figure with a caption that runs for more than one line.
    Example image is usually available through the \texttt{mwe} package
    without even mentioning it in the preamble.}
  \label{fig:experiments}
\end{figure}

\begin{figure*}[t]
  \includegraphics[width=0.48\linewidth]{example-image-a} \hfill
  \includegraphics[width=0.48\linewidth]{example-image-b}
  \caption {A minimal working example to demonstrate how to place
    two images side-by-side.}
\end{figure*}

\subsection{Citations}

\begin{table*}
  \centering
  \begin{tabular}{lll}
    \hline
    \textbf{Output}           & \textbf{natbib command} & \textbf{ACL only command} \\
    \hline
    \citep{Gusfield:97}       & \verb|\citep|           &                           \\
    \citealp{Gusfield:97}     & \verb|\citealp|         &                           \\
    \citet{Gusfield:97}       & \verb|\citet|           &                           \\
    \citeyearpar{Gusfield:97} & \verb|\citeyearpar|     &                           \\
    \citeposs{Gusfield:97}    &                         & \verb|\citeposs|          \\
    \hline
  \end{tabular}
  \caption{\label{citation-guide}
    Citation commands supported by the style file.
  }
\end{table*}

Table~\ref{citation-guide} shows the syntax supported by the style files.
We encourage you to use the natbib styles.
You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

\subsection{References}

\nocite{Ando2005,andrew2007scalable,rasooli-tetrault-2015}

Many websites where you can find academic papers also allow you to export a bib file for citation or bib formatted entry. Copy this into the \texttt{custom.bib} and you will be able to cite the paper in the \LaTeX{}. You can remove the example entries.

\subsection{Equations}

An example equation is shown below:
\begin{equation}
  \label{eq:example}
  A = \pi r^2
\end{equation}

Labels for equation numbers, sections, subsections, figures and tables
are all defined with the \verb|\label{label}| command and cross references
to them are made with the \verb|\ref{label}| command.
This an example cross-reference to Equation~\ref{eq:example}. You can also write equations inline, like this: $A=\pi r^2$.

% \section*{Limitations}
\end{comment}
\section*{Team Contributions}

\noindent \textbf{Claire Nielsen} handled the research into related works and strategies, and wrote the Progress Report. \newline

\noindent \textbf{Rebecca Di Filippo} and \textbf{Jake Read} handled the coding of the model up to this point in the project. Rebecca handled the preprocessing of the dataset, feature engineering and selection, and Baseline Model for comparison. Jake wrote the starting gradient boosting algorithm, loss function, and optimization technique. Rebecca and Jake collaborated on the evaluation strategies for the model (including the training/testing split, cross-validation, and metrics). 

\section*{Repository Link}
\noindent Our GitHub repository can be found \href{https://github.com/rebeccadifilippo/ML_project}{here}.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{custom,anthology-overleaf-1,anthology-overleaf-2}

% Custom bibliography entries only
\bibliography{custom}

% \appendix

% \section{Example Appendix}
% \label{sec:appendix}

% This is an appendix.

\end{document}
